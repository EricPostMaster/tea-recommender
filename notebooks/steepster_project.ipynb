{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Import packages\n",
    "############################################\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "from parsel import Selector\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from datetime import date\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import re\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from pyvis.network import Network\n",
    "import math\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### First function is to create the first entry in the user_dict\n",
    "#### starts with jack by default, but could be changed in initialization\n",
    "# install webdriver\n",
    "# create user_dict variable\n",
    "# go to jack page 1\n",
    "# get follower and following count and pages\n",
    "\n",
    "\n",
    "\n",
    "# Second function is to use that person's followers to add new users to the user_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Build list of all connected users\n",
    "############################################\n",
    "\n",
    "# Creates driver that is updated to work with the latest version of Chrome\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "# Navigate to Jack's page (user #1)\n",
    "driver.get('https://steepster.com/jack/followers?page=1')\n",
    "\n",
    "all_urls = []\n",
    "\n",
    "current_user = 'jack'\n",
    "\n",
    "user_dict = {current_user:{}}\n",
    "\n",
    "follower_count = int(driver.find_element_by_id('follower_count').text)\n",
    "max_follower_pg = int(math.ceil(follower_count / 10.0))\n",
    "\n",
    "user_dict[current_user]['follower_count'] = follower_count\n",
    "user_dict[current_user]['follower_pgs'] = max_follower_pg\n",
    "\n",
    "following_count = int(driver.find_element_by_id('following_count').text)\n",
    "# max_following_pg = int(round(following_count,-1)/10)\n",
    "max_following_pg = int(math.ceil(following_count / 10.0))\n",
    "\n",
    "user_dict[current_user]['following_count'] = following_count\n",
    "user_dict[current_user]['following_pgs'] = max_following_pg\n",
    "\n",
    "# user_id = driver.find_elements_by_css_selector(\"h1>a\")\n",
    "\n",
    "# for id_info in user_id:\n",
    "#     user_id = id_info.get_attribute('data-leader-id')\n",
    "\n",
    "follower_urls = []\n",
    "# This list will be attached as the followers to the user\n",
    "# It will also become the list from which we work to pull names to grow the network\n",
    "\n",
    "ff_counts = []\n",
    "\n",
    "for j in range(1,min(max_follower_pg+1,2)):\n",
    "    print('now reading ', current_user, ' page ', j)\n",
    "    \n",
    "    # if we're on page 1, keep going. Otherwise, load the next page\n",
    "    if j == 1:\n",
    "        pass\n",
    "    else:\n",
    "        driver.get(f'https://steepster.com/{current_user}/followers?page={j}')\n",
    "\n",
    "    # Get all user urls from the current page\n",
    "    all_links = driver.find_elements_by_css_selector(\".users>.user>.details>a\")\n",
    "\n",
    "    # For users who aren't in the user_dict yet, so I need to get their followers\n",
    "    need_followers = []\n",
    "\n",
    "    \n",
    "    for link in all_links:\n",
    "        user_link = link.get_attribute(\"href\")\n",
    "        m = re.search(r\"(?<=\\.com\\/).*\", user_link)\n",
    "        follower_urls.append(m.group(0))  # User url: 'jack', 'mike276', etc.\n",
    "\n",
    "        print('current_follower: ', m.group(0))\n",
    "        # print('Current user_dict list: ', user_dict.keys())\n",
    "\n",
    "        # If the user isn't already in the dictionary, add it to a list to add later\n",
    "        if m.group(0) not in user_dict.keys():\n",
    "            print('User is not in user_dict')\n",
    "            if len(all_urls) > 0:\n",
    "                all_urls.append(m.group(0))\n",
    "            # Don't add to dictionary yet. I'll do that with the zipped lists later\n",
    "            need_followers.append(m.group(0))\n",
    "        else:\n",
    "            print(\"This user is already in the user_dict\")\n",
    "    print('need_followers for ',current_user,': ',need_followers)\n",
    "    \n",
    "    # need to just get both of these at the same time. They share a CSS root\n",
    "    follower_followers = driver.find_elements_by_css_selector(\".users>.user>.details>em\")\n",
    "\n",
    "    for count in follower_followers:\n",
    "        ff_count = int(count.get_attribute(\"data-pluralize-count\"))\n",
    "        ff_counts.append(ff_count)\n",
    "\n",
    "    # zip the lists together\n",
    "    zipped_ff_list = list(zip(follower_urls, ff_counts))\n",
    "\n",
    "    print('Followers who are not in the user_dict and their follower count:\\n', zipped_ff_list)\n",
    "\n",
    "    # Add new users and their follower counts to the user_dict\n",
    "    for user, user_ff_count in zipped_ff_list:\n",
    "        print('First user in zipped_ff_list: ', user)\n",
    "        if user in need_followers:\n",
    "            print('adding ',user,' to user_dict')\n",
    "            user_dict[user] = {}\n",
    "            user_dict[user]['follower_count'] = user_ff_count\n",
    "            max_follower_pg = int(math.ceil(user_dict[user]['follower_count'] / 10.0))\n",
    "            user_dict[user]['follower_pgs'] = max_follower_pg\n",
    "        else:\n",
    "            print(user,' is already in user_dict')\n",
    "        # time.sleep(3)\n",
    "\n",
    "# follower_urls is added to the current user's dict entry\n",
    "user_dict[current_user]['followers'] = follower_urls\n",
    "\n",
    "# all_urls = follower_urls\n",
    "all_urls = list(user_dict.keys())\n",
    "# Now go to the next follower page\n",
    "\n",
    "time.sleep(0.5)\n",
    "\n",
    "# Close browser and terminate driver instance\n",
    "driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follower_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# Build list of all connected users\n",
    "############################################\n",
    "\n",
    "# UserDict should be a class, and create_user_dict should be the __init__ fxn\n",
    "\n",
    "# def create_user_dict():\n",
    "#     user_dict = {}\n",
    "#     return user_dict\n",
    "\n",
    "def get_first_user(username='jack'):\n",
    "\n",
    "    # Creates driver that is updated to work with the latest version of Chrome\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "    # Navigate to Jack's page (user #1)\n",
    "    driver.get(f'https://steepster.com/{username}/followers?page=1')\n",
    "\n",
    "    all_urls = []\n",
    "\n",
    "    current_user = username\n",
    "\n",
    "    user_dict = {current_user:{}}\n",
    "\n",
    "    follower_count = int(driver.find_element_by_id('follower_count').text)\n",
    "    max_follower_pg = int(math.ceil(follower_count / 10.0))\n",
    "\n",
    "    user_dict[current_user]['follower_count'] = follower_count\n",
    "    user_dict[current_user]['follower_pgs'] = max_follower_pg\n",
    "\n",
    "    following_count = int(driver.find_element_by_id('following_count').text)\n",
    "    # max_following_pg = int(round(following_count,-1)/10)\n",
    "    max_following_pg = int(math.ceil(following_count / 10.0))\n",
    "\n",
    "    user_dict[current_user]['following_count'] = following_count\n",
    "    user_dict[current_user]['following_pgs'] = max_following_pg\n",
    "\n",
    "    # user_id = driver.find_elements_by_css_selector(\"h1>a\")\n",
    "\n",
    "    # for id_info in user_id:\n",
    "    #     user_id = id_info.get_attribute('data-leader-id')\n",
    "\n",
    "    follower_urls = []\n",
    "    # This list will be attached as the followers to the user\n",
    "    # It will also become the list from which we work to pull names to grow the network\n",
    "\n",
    "    ff_counts = []\n",
    "\n",
    "    for j in range(1,min(max_follower_pg+1,2)):\n",
    "        print('now reading ', current_user, ' page ', j)\n",
    "        \n",
    "        # if we're on page 1, keep going. Otherwise, load the next page\n",
    "        if j == 1:\n",
    "            pass\n",
    "        else:\n",
    "            driver.get(f'https://steepster.com/{current_user}/followers?page={j}')\n",
    "\n",
    "\n",
    "        # this is where the common xpath goes\n",
    "        # user_div = driver.find_elements_by_xpath(\"//div[@class='user']\")\n",
    "\n",
    "        # Get all user urls from the current page\n",
    "        all_links = driver.find_elements_by_css_selector(\".users>.user>.details>a\")\n",
    "\n",
    "        # For users who aren't in the user_dict yet, so I need to get their followers\n",
    "        need_followers = []\n",
    "\n",
    "        \n",
    "        for link in all_links:\n",
    "            user_link = link.get_attribute(\"href\")\n",
    "            m = re.search(r\"(?<=\\.com\\/).*\", user_link)\n",
    "            follower_urls.append(m.group(0))  # User url: 'jack', 'mike276', etc.\n",
    "\n",
    "            print('current_follower: ', m.group(0))\n",
    "            # print('Current user_dict list: ', user_dict.keys())\n",
    "\n",
    "            # If the user isn't already in the dictionary, add it to a list to add later\n",
    "            if m.group(0) not in user_dict.keys():\n",
    "                print('User is not in user_dict')\n",
    "                if len(all_urls) > 0:\n",
    "                    all_urls.append(m.group(0))\n",
    "                # Don't add to dictionary yet. I'll do that with the zipped lists later\n",
    "                need_followers.append(m.group(0))\n",
    "            else:\n",
    "                print(\"This user is already in the user_dict\")\n",
    "        print('need_followers for ',current_user,': ',need_followers)\n",
    "        \n",
    "        # need to just get both of these at the same time. They share a CSS root\n",
    "        follower_followers = driver.find_elements_by_css_selector(\".users>.user>.details>em\")\n",
    "\n",
    "        for count in follower_followers:\n",
    "            ff_count = int(count.get_attribute(\"data-pluralize-count\"))\n",
    "            ff_counts.append(ff_count)\n",
    "\n",
    "        # zip the lists together\n",
    "        zipped_ff_list = list(zip(follower_urls, ff_counts))\n",
    "\n",
    "        print('Followers who are not in the user_dict and their follower count:\\n', zipped_ff_list)\n",
    "\n",
    "        # Add new users and their follower counts to the user_dict\n",
    "        for user, user_ff_count in zipped_ff_list:\n",
    "            print('First user in zipped_ff_list: ', user)\n",
    "            if user in need_followers:\n",
    "                print('adding ',user,' to user_dict')\n",
    "                user_dict[user] = {}\n",
    "                user_dict[user]['follower_count'] = user_ff_count\n",
    "                max_follower_pg = int(math.ceil(user_dict[user]['follower_count'] / 10.0))\n",
    "                user_dict[user]['follower_pgs'] = max_follower_pg\n",
    "            else:\n",
    "                print(user,' is already in user_dict')\n",
    "            # time.sleep(3)\n",
    "\n",
    "    # follower_urls is added to the current user's dict entry\n",
    "    user_dict[current_user]['followers'] = follower_urls\n",
    "\n",
    "    all_urls = follower_urls\n",
    "    # Now go to the next follower page\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # Close browser and terminate driver instance\n",
    "    driver.quit()\n",
    "\n",
    "    return user_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = get_first_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to advance current user down the list of users,\n",
    "\n",
    "i = 0\n",
    "\n",
    "# for i in range(0,len(all_urls)+1):\n",
    "\n",
    "# this is the number of new users I want to add to the user_dict\n",
    "while i <= 15: # len(all_urls)+1:\n",
    "    current_user = all_urls[i]\n",
    "\n",
    "    print('---------------------\\ncurrent_user: ',current_user)\n",
    "    print('---------------------\\nall_urls index: ',i)\n",
    "\n",
    "    # Check if current user already has followers before doing anything else\n",
    "    # if current_user in list(user_dict.keys()):\n",
    "    #     print(f'{current_user} is already in the user_dict')\n",
    "    #     pass\n",
    "    # else:\n",
    "\n",
    "\n",
    "\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "    # Navigate to user's followers page\n",
    "    driver.get(f'https://steepster.com/{current_user}/followers?page=1')\n",
    "\n",
    "    # Set max follower and following pages\n",
    "    max_follower_pg = user_dict[current_user]['follower_pgs']\n",
    "\n",
    "    following_count = int(driver.find_element_by_id('following_count').text)\n",
    "    # max_following_pg = int(round(following_count,-1)/10)\n",
    "    max_following_pg = int(math.ceil(following_count / 10.0))\n",
    "    \n",
    "    follower_urls = []\n",
    "\n",
    "    for j in range(1, min(max_follower_pg+1,4)):\n",
    "        print('now reading ', current_user, ' page ', j)\n",
    "\n",
    "        # Saves a reload of the first page for every user\n",
    "        if j == 1:\n",
    "            pass\n",
    "        else:\n",
    "            driver.get(f'https://steepster.com/{current_user}/followers?page={j}')\n",
    "\n",
    "        # Retrieve URLs for followers\n",
    "        all_links = driver.find_elements_by_css_selector(\".users>.user>.details>a\")\n",
    "        \n",
    "        # For users who aren't in the user_dict yet, so I need to get their followers\n",
    "        need_followers = []\n",
    "        page_follower_urls = []\n",
    "        ff_counts = []\n",
    "\n",
    "        # Parse usernames from href (e.g., 'jack' from 'steepster.com/jack')\n",
    "        for link in all_links:\n",
    "            user_link = link.get_attribute(\"href\")\n",
    "            m = re.search(r\"(?<=\\.com\\/).*\", user_link)\n",
    "            follower_urls.append(m.group(0))\n",
    "            page_follower_urls.append(m.group(0))\n",
    "            # if url not in user_dict keys, append to all_urls\n",
    "\n",
    "            print('current_follower: ', m.group(0))\n",
    "            # print('Current user_dict list: ', user_dict.keys())\n",
    "            \n",
    "\n",
    "            if m.group(0) not in user_dict.keys():\n",
    "                print('User is not in user_dict')\n",
    "                if len(all_urls) > 0:\n",
    "                    all_urls.append(m.group(0))\n",
    "                # Don't add to dictionary yet. I'll do that with the zipped lists later\n",
    "                need_followers.append(m.group(0))\n",
    "            else:\n",
    "                print(\"This user is already in the user_dict\")\n",
    "        print('need_followers for ',current_user,': ',need_followers)\n",
    "        \n",
    "        # if url not in all_urls, add to a list to get number of followers\n",
    "        follower_followers = driver.find_elements_by_css_selector(\".users>.user>.details>em\")\n",
    "\n",
    "        for count in follower_followers:\n",
    "            ff_count = int(count.get_attribute(\"data-pluralize-count\"))\n",
    "            ff_counts.append(ff_count)\n",
    "        \n",
    "        # zip the lists together\n",
    "        zipped_ff_list = list(zip(page_follower_urls, ff_counts))\n",
    "\n",
    "        print('Followers who are not in the user_dict and their follower count:\\n', zipped_ff_list)\n",
    "\n",
    "        for user, user_ff_count in zipped_ff_list:\n",
    "            print('User in zipped_ff_list: ', user)\n",
    "            if user in need_followers:\n",
    "                print('adding ',user,' to user_dict')\n",
    "                user_dict[user] = {}\n",
    "                user_dict[user]['follower_count'] = user_ff_count\n",
    "                max_follower_pg = int(math.ceil(user_dict[user]['follower_count'] / 10.0))\n",
    "                user_dict[user]['follower_pgs'] = max_follower_pg\n",
    "            else:\n",
    "                print(user,' is already in user_dict')\n",
    "            # time.sleep(3)\n",
    "\n",
    "    user_dict[current_user]['followers'] = follower_urls\n",
    "\n",
    "    # Increment i to move to next user once browser closes\n",
    "    i+=1\n",
    "\n",
    "    print('---------------------\\nall_urls: ',all_urls)\n",
    "\n",
    "    # Close browser and terminate driver instance\n",
    "    driver.quit()\n",
    "\n",
    "    time.sleep(0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build edgelist from user_dict keys and follower lists\n",
    "edges = []\n",
    "\n",
    "for key in user_dict.keys():\n",
    "    for subkey in user_dict[key].keys():\n",
    "        if subkey == 'followers':\n",
    "            for element in user_dict[key][subkey]:\n",
    "                edges.append((element,key))\n",
    "\n",
    "# refactor this into a gnarly list comprehension at some point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.DiGraph(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(16,9))\n",
    "plt.margins(.2,.2)\n",
    "nx.draw(g\n",
    "        ,pos=nx.spring_layout(g)\n",
    "        ,with_labels=True\n",
    "        ,node_color='lightblue'\n",
    "        ,node_size=600\n",
    "        ,edge_color='gray'\n",
    "        ,width=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pyvis Network object\n",
    "net = Network(height = \"600px\", width = \"800px\", notebook = True)\n",
    "net.from_nx(g)\n",
    "net.show_buttons()\n",
    "net.show('net1.html')\n",
    "# Turn on the \"To\" arrows to see who follows who."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Followers and Following ##########\n",
    "# Number of followers\n",
    "# get the value from the #id follower_count\n",
    "\n",
    "# Number of pages needed to get all followers\n",
    "# Round up follower_count to the nearest 10 and then divide by 10\n",
    "\n",
    "# Number following\n",
    "# get the value from the #id following_count\n",
    "\n",
    "# Number of pages needed to get all following\n",
    "# Round up following_count to the nearest 10 and then divide by 10\n",
    "\n",
    "\n",
    "########## Get Follower Names ##########\n",
    "# div class users, div class user - the id of that div is the unique user id\n",
    "# If the unique user id is not in the dictionary of user ids,\n",
    "#   then add the user id and the url and display names below\n",
    "\n",
    "# div class users, div class user, div class details, a href is the url\n",
    "# div class users, div class user, div class details, a content is the display name\n",
    "\n",
    "\n",
    "#{\n",
    "# 1:{followers:##,\n",
    "#    following:##,\n",
    "#    teas_rated:##,\n",
    "#    url:'/jack'\n",
    "#    display_name:'Jack'}\n",
    "# 2:{followers:##,\n",
    "#    following:##,\n",
    "#    teas_rated:##,\n",
    "#    url:'/mike'\n",
    "#    display_name:'Mike'}\n",
    "#}\n",
    "\n",
    "\n",
    "# Navigate to follower page\n",
    "# Make a list of all ids in the \"user\" class divs\n",
    "# Remove follower user ids that are already in the dictionary\n",
    "# Add remaining user ids to the dictionary as keys with url, display_name\n",
    "\n",
    "# Navigate to next follower page and repeat\n",
    "\n",
    "# What does it do when it gets to the end of the followers?\n",
    "# Exit the loop\n",
    "# Start on the following page\n",
    "\n",
    "\n",
    "# Will need to chunk this out, like do 1,000 users at a time so I can save the dataset as I go\n",
    "# Log the progress somewhere\n",
    "\n",
    "# Should probably test it out on a small account, like my own.\n",
    "# I can just follow 15 people and test it out.\n",
    "\n",
    "# Write logic for someone who has zero followers or zero following (e.g., me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a quick for loop test to make sure it recalculated the length of murph every time\n",
    "# Turns out, it is not. I need to find a way around that.\n",
    "# Could try a while loop, like while i <= len(murph), keep going\n",
    "\n",
    "murph = [1,2,3]\n",
    "\n",
    "j = 4\n",
    "i=0\n",
    "\n",
    "for i in range(0,len(murph)):\n",
    "# while i <= len(murph):\n",
    "    print('i:',i,', len(murph):',len(murph))\n",
    "    print(murph)\n",
    "    murph.append(j)\n",
    "    j+=1\n",
    "    # print(j)\n",
    "    i+=1\n",
    "    # print('i=',i)\n",
    "    # print('j=',j)\n",
    "    if j >= 10:\n",
    "        print('Stop. j=',j)\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can re-run the code to get followers from the all_urls list,\n",
    "# and it will append new followers on to existing users! Awesome.\n",
    "# To make this more efficient (although it still could be better),\n",
    "# I could check the new max_follower_pg to see if it's different from what\n",
    "# is in the user_dict entry for that person. If it's bigger, then I could\n",
    "# just start the scraping function from there. It would be an update_user() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping tea reviews should be much simpler because I'm just going to work\n",
    "# from the list of teas, sorted by popularity. I don't have to build an \"all_urls\"\n",
    "# sort of list to tell the code where to look next to find more tea.\n",
    "\n",
    "##### get_tea_list #####\n",
    "# Navigate to https://steepster.com/teas?sort=popular (sort by popularity to maximize early results)\n",
    "#   Count the number of \"product tea\" class elements to loop through\n",
    "#   count = len(driver.find_elements_by_class_name('your_class_name'))\n",
    "\n",
    "# Tea Name: div .\"products\" > div .\"product tea\" > div .\"tea\" > a .\"tea-name\" text\n",
    "# Brand: div .\"products\" > div .\"product tea\" > div .\"tea\" > a .\"tea-name\" > em\n",
    "# Rating div .\"products\" > div .\"product tea\" > div .\"tea\" > div .\"tea-rating awesome\" text\n",
    "# Link div .\"products\" > div .\"product tea\" > div .\"tea\" > a get href\n",
    "\n",
    "# Note: There are 28 teas per page\n",
    "\n",
    "# after scraping the list of teas, get reviews for each tea:\n",
    "\n",
    "##### get_tea_reviews #####\n",
    "#https://steepster.com/teas/davidstea/10338-forever-nuts?page=2#tasting-notes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "\n",
    "file_exists = exists('..\\\\data\\pickled-data\\\\tea_dict.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tea_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tea_pages_to_scrape = 1\n",
    "\n",
    "tea_dict = {}\n",
    "\n",
    "for i in range(1,tea_pages_to_scrape+1):\n",
    "\n",
    "    # Creates driver that is updated to work with the latest version of Chrome\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    driver.get(f'https://steepster.com/teas?page={i}&sort=popular')\n",
    "\n",
    "    name_selectors = '.products>.product>.tea>.tea-name'\n",
    "    tea_names = driver.find_elements_by_css_selector(name_selectors)\n",
    "\n",
    "    names_to_zip = []\n",
    "\n",
    "    for tea in tea_names:\n",
    "        nb = tea.text.split('\\n')\n",
    "        name = nb[0]\n",
    "        names_to_zip.append(name)\n",
    "        tea_dict[name] = {}\n",
    "\n",
    "        brand = nb[1]\n",
    "        tea_dict[name]['brand'] = brand\n",
    "\n",
    "        tea_link = tea.get_attribute(\"href\")\n",
    "        tea_dict[name]['url'] = tea_link\n",
    "\n",
    "    rating_selectors = '.products>.product>.tea>.tea-rating'\n",
    "    tea_ratings = driver.find_elements_by_css_selector(rating_selectors)\n",
    "\n",
    "    ratings_to_zip = []\n",
    "\n",
    "    for tea in tea_ratings:\n",
    "        rating = int(tea.text)\n",
    "        ratings_to_zip.append(rating)\n",
    "        # tea_dict[name]['rating'] = rating\n",
    "\n",
    "    zipped_ratings = list(zip(names_to_zip,ratings_to_zip))\n",
    "\n",
    "    for element in zipped_ratings:\n",
    "        tea_dict[element[0]]['rating'] = element[1]\n",
    "\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    time.sleep(0.25)\n",
    "\n",
    "# Need to write something that can pick up where ever this left off,\n",
    "# like dividing the number of keys by 28 and then adding 1 to keep going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIXING THE ZIP THING HERE\n",
    "### PROBLEM WITH THE XPATH, BUT I GOT RID OF THE ZIP THING ABOVE\n",
    "\n",
    "tea_pages_to_scrape = 2\n",
    "\n",
    "# tea_dict = {}\n",
    "\n",
    "for i in range(1,tea_pages_to_scrape+1):\n",
    "\n",
    "    # Creates driver that is updated to work with the latest version of Chrome\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    driver.get(f'https://steepster.com/teas?page={i}&sort=popular')\n",
    "\n",
    "    # tea_xpath = \"//div[@class='products']//div[@class='product']//div[@class='tea']\"\n",
    "    tea_xpath = \"//div[@class='product tea']//div[@class='tea']\"\n",
    "\n",
    "    tea_root =  driver.find_elements_by_xpath(tea_xpath)\n",
    "\n",
    "    for tea in tea_root:\n",
    "\n",
    "        tea_info = []\n",
    "\n",
    "        # Tea Name\n",
    "        tea_name_xpath = \".//a[@class='tea-name']\"\n",
    "        tea_name = tea.find_element_by_xpath(tea_name_xpath)\n",
    "\n",
    "        # for tea in tea_name:\n",
    "        nb = tea.text.split('\\n')\n",
    "        name = nb[0]\n",
    "\n",
    "        # Check if tea is already in tea_dict\n",
    "        if name in tea_dict.keys():\n",
    "            print(f'{name} skipped. Already in tea_dict.')\n",
    "            pass\n",
    "        else:\n",
    "            tea_dict[name] = {}\n",
    "            print('name:', name)\n",
    "\n",
    "            brand = nb[1]\n",
    "            tea_dict[name]['brand'] = brand\n",
    "            print('brand:', brand)\n",
    "\n",
    "            tea_link = tea.get_attribute(\"href\")\n",
    "            tea_dict[name]['url'] = tea_link\n",
    "\n",
    "            # Tea Rating\n",
    "            tea_rating_xpath = \".//div[contains(@class, 'tea-rating')]\"\n",
    "            tea_rating = tea.find_element_by_xpath(tea_rating_xpath)\n",
    "\n",
    "            # for tea in tea_rating:\n",
    "            rating = int(tea_rating.text)\n",
    "            tea_dict[name]['rating'] = rating\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    time.sleep(0.25)\n",
    "\n",
    "# Need to write something that can pick up where ever this left off,\n",
    "# like dividing the number of keys by 28 and then adding 1 to keep going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tea_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for tea in tea_dict.keys():\n",
    "\n",
    "    print('Current tea:',tea)\n",
    "\n",
    "    tea_dict[tea]['reviewers'] = {}\n",
    "\n",
    "    tea_url = tea_dict[tea]['url']\n",
    "\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    driver.get(f'{tea_url}?page=1#tasting-notes')\n",
    "    time.sleep(1)\n",
    "\n",
    "    max_pages = driver.find_elements_by_xpath(\"//nav[@class='pagination']//ul//li[last()-1]//a\")\n",
    "    for page in max_pages:\n",
    "        max_review_pgs = int(page.text)\n",
    "        tea_dict[tea]['review_pages'] = max_review_pgs\n",
    "\n",
    "\n",
    "    for i in range(1, min(5,max_review_pgs)):\n",
    "\n",
    "        # Only need this for >1 because we are already on the page\n",
    "        if i > 1:\n",
    "            driver.get(f'{tea_url}?page={i}#tasting-notes')\n",
    "\n",
    "        all_user_elements = []\n",
    "\n",
    "        user_div = driver.find_elements_by_xpath(\"//div[@class='user']\")\n",
    "\n",
    "        for user in user_div:\n",
    "\n",
    "            user_info = []\n",
    "\n",
    "            # Reviewer\n",
    "            r = user.find_element_by_xpath(\".//span[@itemprop='author']//a[@itemprop='url']\")\n",
    "            r_url = r.get_attribute('href')\n",
    "            reviewer = re.search(r\"(?<=\\.com\\/).*\", r_url)\n",
    "            user_info.append(reviewer.group(0))\n",
    "\n",
    "            # Rating\n",
    "            try:\n",
    "                r = user.find_element_by_xpath(\".//div[@itemprop='reviewRating']//span[@itemprop='ratingValue']\")\n",
    "                rating = int(r.text)\n",
    "                user_info.append(rating)\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "\n",
    "            if len(user_info) == 2:\n",
    "                all_user_elements.append(user_info)\n",
    "                tea_dict[tea]['reviewers'][user_info[0]] = {}\n",
    "                tea_dict[tea]['reviewers'][user_info[0]]['weight'] = user_info[1]\n",
    "\n",
    "        \n",
    "    driver.quit()\n",
    "        \n",
    "    time.sleep(0.5)\n",
    "\n",
    "    print(tea,'complete')\n",
    "    print('-----------------------\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/pickled-data/tea_dict.p\", 'rb') as p:\n",
    "    tea_dict = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "\n",
    "for tea in tea_dict.keys():\n",
    "    for tea_char in tea_dict[tea].keys():\n",
    "        if tea_char == 'reviewers':\n",
    "            for reviewer in tea_dict[tea][tea_char].keys():\n",
    "                edges.append((reviewer, tea, tea_dict[tea][tea_char][reviewer]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = nx.DiGraph(edges)\n",
    "G = nx.Graph(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_nodes = set([edge[0] for edge in edges])\n",
    "colors = ['C0' if i in source_nodes else 'C1' for i in T.nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(25,10))\n",
    "plt.margins(.2,.2)\n",
    "nx.draw(T\n",
    "        ,pos=nx.spring_layout(T)\n",
    "        ,with_labels=False\n",
    "        ,node_color=colors\n",
    "        ,node_size=20\n",
    "        ,edge_color='gray'\n",
    "        ,width=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(10,20))\n",
    "plt.margins(.2,.2)\n",
    "nx.draw(T\n",
    "        ,pos=nx.bipartite_layout(T, source_nodes)\n",
    "        ,with_labels=False\n",
    "        ,node_color=colors\n",
    "        ,node_size=20\n",
    "        ,edge_color='gray'\n",
    "        ,width=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(height = \"600px\", width = \"800px\", notebook = True)\n",
    "net.from_nx(T)\n",
    "net.show_buttons()\n",
    "net.show('net2.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T['Aedon2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_weights = []\n",
    "\n",
    "for i in list(T.edges(data=True)):\n",
    "    for key in i[2]:\n",
    "        edge_weights.append(i[2][key]/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tea_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tea_scraper import TeaDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teas = TeaDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 102.0.5005\n",
      "Get LATEST driver version for 102.0.5005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current tea: Forever Nuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Driver [C:\\Users\\ericd\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start page: 4\n",
      "Forever Nuts has 36 existing reviews.\n",
      "Adding new reviews starting on page 4.\n",
      "Previous review count: 36\n",
      "New review count: 44\n",
      "8 reviews added to Forever Nuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 102.0.5005\n",
      "Get LATEST driver version for 102.0.5005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forever Nuts complete\n",
      "-----------------------\n",
      "\n",
      "Current tea: Pumpkin Chai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Driver [C:\\Users\\ericd\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start page: 4\n",
      "Pumpkin Chai has 34 existing reviews.\n",
      "Adding new reviews starting on page 4.\n",
      "Previous review count: 34\n",
      "New review count: 43\n",
      "9 reviews added to Pumpkin Chai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 102.0.5005\n",
      "Get LATEST driver version for 102.0.5005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pumpkin Chai complete\n",
      "-----------------------\n",
      "\n",
      "Current tea: Read My Lips\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Driver [C:\\Users\\ericd\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: cannot determine loading status\nfrom disconnected: received Inspector.detached event\n  (Session info: chrome=102.0.5005.115)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-74c1c81218d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# all_teas.get_teas(tea_pages_to_scrape=2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mall_teas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_reviews\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_review_pgs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\ericd\\Documents\\GitHub\\tea-recommender\\notebooks\\tea_scraper.py\u001b[0m in \u001b[0;36mget_reviews\u001b[1;34m(self, min_review_pgs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mChromeDriverManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{tea_url}?page=1#tasting-notes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ericd\\Anaconda3\\envs\\steepster_env\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \"\"\"\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ericd\\Anaconda3\\envs\\steepster_env\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mc:\\Users\\ericd\\Anaconda3\\envs\\steepster_env\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: unknown error: cannot determine loading status\nfrom disconnected: received Inspector.detached event\n  (Session info: chrome=102.0.5005.115)\n"
     ]
    }
   ],
   "source": [
    "# all_teas.get_teas(tea_pages_to_scrape=2)\n",
    "all_teas.get_reviews(min_review_pgs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if 'brand' in all_teas.tea_dict['Forever Nuts'].keys():\n",
    "    # print(all_teas.tea_dict['Forever Nuts']['brand'])\n",
    "    # print(len(all_teas.tea_dict['Forever Nuts']['brand']))\n",
    "# len(all_teas.tea_dict.keys())\n",
    "# ['Forever Nuts', 'Pumpkin Chai', 'Read My Lips',\n",
    "len(all_teas.tea_dict['Forever Nuts']['reviewers'].keys())\n",
    "# all_teas.tea_dict['Forever Nuts']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('steepster_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "079708c688cffb6d047d5ca8f9fc289774d7740768c0ea6a3a0babe77449fb74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
